## **Etap 1 – Podstawowy system człowiek ↔ bot**

**Cel:** Bot potrafi rozmawiać z człowiekiem w czasie rzeczywistym.

1. **Rozpoznawanie mowy (STT)** – np. `speech_recognition`.
2. **Silnik dialogowy AI** – gotowy model (GPT Open AI).
3. **Syntezator mowy (TTS)** – np. `gTTS`.
   **Efekt:** Człowiek mówi → bot rozpoznaje → AI generuje odpowiedź → bot odczytuje odpowiedź głosem.

---

**Tworzenie botów - kazdy jest osobny agentem stworzonym przez polecenie słowne 
i tworzy sie osoban instancja OpenAI ChatGPT
Wszytskie boty są instancjami modelu działającymi równolegle
Myślenie jest dynamiczne - zawsze keidy wywołujemy get_response()

## **Etap 2 – Człowiek + bot + bot (mieszana rozmowa)**

**Cel:** System może prowadzić równoległą rozmowę: człowiek i jeden lub więcej botów.

1. Utrzymanie **równoległych kanałów audio** (ludzie i bota).
2. Logika decydująca, kiedy używać TTS, a kiedy GibberLink.
3. Obsługa jednoczesnej wymiany informacji między botami i człowiekiem.
   **Efekt:** Człowiek rozmawia z botem, a bot równocześnie wymienia informacje z innymi botami.

---

## **Etap 3 – Wstęp do GibberLink: człowiek (normalnie) + bot ↔ bot**

**Cel:** Bot potrafi wykryć innego bota i przełączyć się na komunikację przez GibberLink (GGWave).

1. Integracja GGWave → konwersja tekst → dźwięk i odwrotnie.
2. Logika wykrywająca, że rozmówcą jest inny bot.
3. Wysyłanie i odbieranie danych przez GibberLink zamiast normalnej mowy.
   **Efekt:** Bot może rozmawiać z drugim botem szybciej i efektywniej, używając sygnałów audio, ale tylko wtedy gdy nie ma człowieka !!!

---

## **Etap 4 – Wieloosobowa rozmowa (grupowa)**

**Cel:** Obsługa wielu botów i ludzi w tym samym czasie.

1. Rozdzielanie rozmów i identyfikacja uczestników.
2. Synchronizacja GibberLink + TTS, żeby nie nakładały się głosy.
3. Testy z kilkoma botami i jednym lub więcej ludźmi.
   **Efekt:** System obsługuje rozmowy grupowe, boty wymieniają informacje między sobą przez GibberLink, a ludzie słyszą TTS.

---


WebRTC